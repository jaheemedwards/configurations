# **ds-project-generator**

A lightweight Zsh-based generator for creating a clean, production-ready data science project structure. Automatically sets up directories, boilerplate code, configs, and deployment files for fast project initialization.

---

## **ğŸš€ Usage**

### **1. Place the script in the repo**

Save the script as:

```
create_ds_project.zsh
```

### **2. Make it executable**

```bash
chmod +x create_ds_project.zsh
```

### **3. Run the script**

```bash
./create_ds_project.zsh <project-name>
```

**Example:**

```bash
./create_ds_project.zsh my-awesome-project
```

---

## **ğŸ“ Project Structure Generated**

```
project-name/
â”‚
â”œâ”€â”€ README.md                 # Project overview and documentation
â”œâ”€â”€ LICENSE                   # License file (MIT by default)
â”œâ”€â”€ .gitignore                # Files and folders to exclude from Git
â”œâ”€â”€ pyproject.toml            # Modern Python package + dependency config
â”œâ”€â”€ requirements.txt          # Alternative dependency file
â”œâ”€â”€ Makefile                  # Common automation commands (optional)
â”‚
â”œâ”€â”€ data/                     # All project datasets
â”‚   â”œâ”€â”€ raw/                  # Original data (never modified)
â”‚   â”œâ”€â”€ processed/            # Cleaned/validated datasets
â”‚   â”œâ”€â”€ interim/              # Temporary/partial outputs
â”‚   â””â”€â”€ external/             # Data pulled from APIs/external sources
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks for EDA + experiments
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_model_experiments.ipynb
â”‚   â””â”€â”€ templates/            # Notebook templates
â”‚
â”œâ”€â”€ src/                      # All production Python code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/               # Global YAML/JSON config files
â”‚   â”œâ”€â”€ data/                 # Data ingestion/loading/cleaning logic
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â”œâ”€â”€ transform.py
â”‚   â”‚   â””â”€â”€ extract_api.py
â”‚   â”œâ”€â”€ features/             # Feature engineering scripts
â”‚   â”‚   â””â”€â”€ build_features.py
â”‚   â”œâ”€â”€ models/               # Model training/evaluation/prediction
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â”œâ”€â”€ pipelines/            # Full ETL/ML workflow pipelines
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â””â”€â”€ inference_pipeline.py
â”‚   â”œâ”€â”€ utils/                # Helper utilities (logging, I/O, etc.)
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ file_utils.py
â”‚   â””â”€â”€ api/                  # API for model serving (FastAPI/Flask)
â”‚       â””â”€â”€ app.py
â”‚
â”œâ”€â”€ app/                      # Streamlit application for UI/visualization
â”‚   â”œâ”€â”€ main.py               # Main Streamlit app entry point
â”‚   â”œâ”€â”€ pages/                # Multi-page Streamlit pages
â”‚   â””â”€â”€ components/           # Reusable UI components
â”‚
â”œâ”€â”€ models/                   # Saved ML models (Pickle, ONNX, etc.)
â”‚
â”œâ”€â”€ config/                   # Config files for training + inference
â”‚   â”œâ”€â”€ training.yaml
â”‚   â”œâ”€â”€ inference.yaml
â”‚   â””â”€â”€ data_config.yaml
â”‚
â”œâ”€â”€ tests/                    # Unit tests (pytest)
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ scripts/                  # Automation + CLI scripts
â”‚   â”œâ”€â”€ run_training.sh
â”‚   â”œâ”€â”€ run_inference.sh
â”‚   â””â”€â”€ build_dataset.py
â”‚
â””â”€â”€ deployment/               # Deployment + infrastructure configs
    â”œâ”€â”€ Dockerfile            # Container definition
    â”œâ”€â”€ cloudrun.yaml         # GCP Cloud Run deployment spec
    â”œâ”€â”€ requirements_api.txt  # API-only dependencies
    â””â”€â”€ monitoring/           # Logging/metrics scripts
        â”œâ”€â”€ metrics.py
        â””â”€â”€ logging.py
```

---